{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the third programming assignment for CSCE478/878 Introduction to Machine Learning on Logistic Regression. This notebook is divided into 2 main sections, and 3 subsections each\n",
    "1. **Part A Logistic Regression - Binary Classification**\n",
    "    1. Model Code\n",
    "    1. Load, Partition and Scale Data\n",
    "    1. Model Evaluation\n",
    "1. **Part B Logistic Regression - Multiclass Classification**\n",
    "    1. Model Code\n",
    "    1. Load, Partition and Scale Data\n",
    "    1. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import itertools\n",
    "import math\n",
    "from math import exp\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A-I Model Code Logistic Regression - Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Implement the following function that computes the sigmoid score of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(score):\n",
    "    prob=1/(1+np.exp(-score))\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implement the following function to compute the binary cross-entropy loss\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(Y,Y_proba):\n",
    "    loss=-(np.dot(Y,np.log(Y_proba))+np.dot((1-Y),np.log((1-Y_proba))))/Y.shape[0]\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3. Implement the following function to compute the l2 regularized binary cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy_loss_l2(Y,Y_proba,theta,lambd):\n",
    "    loss=-(np.dot(Y,np.log(Y_proba))+np.dot((1-Y),np.log((1-Y_proba))))/Y.shape[0] + 0.5*lambd*np.dot(theta[1:],theta[1:])/Y.shape[0] \n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Implement the following function to compute the l1 regularized binary cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy_loss_l1(Y,Y_proba,theta,lambd):\n",
    "    loss=-(np.dot(Y,np.log(Y_proba))+np.dot((1-Y),np.log((1-Y_proba))))/Y.shape[0] + lambd*np.sum(abs(theta[1:]))/Y.shape[0] \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Implement a Logistic_Regression_Binary model class. It should have the following three methods. Note the that “fit” method should implement the batch gradient descent algorithm (based on the 1st order derivative of the loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic_Regression_Binary():\n",
    "    def __init__(self, learning_rate=0.01, epochs=100, tol=None, regularizer=None, lambd=0.0, early_stopping=False,validation_fraction=0.1,plotLearningCurve=True, **kwargs):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.tol = tol\n",
    "        self.regularizer = regularizer\n",
    "        self.lambd = lambd\n",
    "        self.w = None\n",
    "        self.loss_train = []\n",
    "        self.loss_validation = []\n",
    "        self.early_stopping = early_stopping\n",
    "        self.early_stopping_iterations = []\n",
    "        self.tolerance_iterations = []\n",
    "        self.validation_fraction = 0.1\n",
    "        self.plotLearningCurve= plotLearningCurve\n",
    "       \n",
    "        return\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # Add x_0 = 1 for all for intercept and concat data\n",
    "        x_0 = np.ones((X.shape[0],1))\n",
    "        X = np.concatenate((x_0,X), axis=1)\n",
    "        \n",
    "        # Initialize all weights to 0\n",
    "        self.w = np.zeros((X.shape[1],))\n",
    "        \n",
    "        if self.plotLearningCurve is True or self.early_stopping is True:\n",
    "            prev_cost= 0\n",
    "            prev_validation_cost=100000\n",
    "            X_train,X_validation,y_train,y_validation =train_test_split(X,y,test_size=self.validation_fraction,shuffle=True)\n",
    "            \n",
    "            # Number of training samples\n",
    "            m = len(X_train)\n",
    "            \n",
    "           # Run batch gradient descent up to self.epoch times\n",
    "            for i in range(self.epochs):\n",
    "                if self.regularizer == \"l2\":\n",
    "                    new_cost= binary_cross_entropy_loss_l2(y_train,sigmoid(X_train.dot(self.w)),self.w,self.lambd)\n",
    "                    self.loss_train.append(new_cost)\n",
    "                    \n",
    "                    new_validation_cost = binary_cross_entropy_loss_l2(y_validation,sigmoid(X_validation.dot(self.w)),self.w,self.lambd)\n",
    "                    self.loss_validation.append(new_validation_cost)\n",
    "                \n",
    "                elif self.regularizer == 'l1':\n",
    "                    new_cost= binary_cross_entropy_loss_l1(y_train,sigmoid(X_train.dot(self.w)),self.w,self.lambd)\n",
    "                    self.loss_train.append(new_cost)\n",
    "                    \n",
    "                    new_validation_cost = binary_cross_entropy_loss_l1(y_validation,sigmoid(X_validation.dot(self.w)),self.w,self.lambd)\n",
    "                    self.loss_validation.append(new_validation_cost)\n",
    "                else:\n",
    "                    # Calculate loss with current weights\n",
    "                    new_cost = binary_cross_entropy(y_train,sigmoid(X_train.dot(self.w)))\n",
    "                    self.loss_train.append(new_cost)\n",
    "                    \n",
    "                    # Calculate loss of validation data\n",
    "                    new_validation_cost = binary_cross_entropy(y_validation,sigmoid(X_validation.dot(self.w)))\n",
    "                    self.loss_validation.append(new_validation_cost)\n",
    "            \n",
    "              # Break if absolute cost of previous cost and current cost is smaller than self.tol\n",
    "                if self.tol is not None:\n",
    "                    if abs(prev_cost - new_cost) > self.tol:\n",
    "                        prev_cost = new_cost\n",
    "                    else:\n",
    "                        self.tolerance_iterations = i # number of iterations for satisfying the tolerance\n",
    "                        print('Early stopping because the tolerance is met')\n",
    "                        break\n",
    "                    \n",
    "               # Break if validation loss is increasing (overfitting)\n",
    "                if self.early_stopping is True:\n",
    "                    if new_validation_cost < prev_validation_cost:\n",
    "                        prev_validation_cost = new_validation_cost\n",
    "                    else:\n",
    "                        self.early_stopping_iterations = i # number of iterations for early stopping\n",
    "                        print('Early stopping because the validation loss is not decreasing')\n",
    "                        break\n",
    "                    \n",
    "               # Calculate gradient   \n",
    "                grad = (X_train.T.dot(sigmoid(X_train.dot(self.w))-y_train))\n",
    "            \n",
    "               # Apply Regularization term to gradient\n",
    "                if self.regularizer == \"l2\":\n",
    "                    regularized_term = self.lambd*self.w\n",
    "                    regularized_term[0] = 0 # Exclude the bias term\n",
    "                    grad = grad + regularized_term\n",
    "                \n",
    "                elif self.regularizer == 'l1':\n",
    "                    regularized_term = self.lambd * np.sign(self.w)\n",
    "                    regularized_term[0] = 0 # Exclude the bias term\n",
    "                    grad = grad + regularized_term\n",
    "            \n",
    "                # Update weights\n",
    "                    self.w = self.w - (self.learning_rate/m)*grad\n",
    "      \n",
    "        else:\n",
    "            # Number of training samples\n",
    "            m = len(X)\n",
    "            \n",
    "            prev_cost= 0\n",
    "            \n",
    "           # Run batch gradient descent up to self.epoch times\n",
    "            for i in range(self.epochs):\n",
    "                if self.regularizer == \"l2\":\n",
    "                    new_cost= binary_cross_entropy_loss_l2(y,sigmoid(X.dot(self.w)),self.w,self.lambd)\n",
    "                \n",
    "                elif self.regularizer == 'l1':\n",
    "                    new_cost= binary_cross_entropy_loss_l1(y,sigmoid(X.dot(self.w)),self.w,self.lambd)\n",
    "              \n",
    "                else:\n",
    "                    # Calculate loss with current weights\n",
    "                    new_cost = binary_cross_entropy(y,sigmoid(X.dot(self.w)))\n",
    "            \n",
    "              # Break if absolute cost of previous cost and current cost is smaller than self.tol\n",
    "                if self.tol is not None:\n",
    "                    if abs(prev_cost - new_cost) > self.tol:\n",
    "                        prev_cost = new_cost\n",
    "                    else:\n",
    "                        self.tolerance_iterations = i # number of iterations for satisfying the tolerance\n",
    "                        print('Early stopping because the tolerance is met')\n",
    "                        break\n",
    "                    \n",
    "               # Calculate gradient   \n",
    "                grad = (X.T.dot(sigmoid(X.dot(self.w))-y))\n",
    "            \n",
    "               # Apply Regularization term to gradient\n",
    "                if self.regularizer == \"l2\":\n",
    "                    regularized_term = self.lambd*self.w\n",
    "                    regularized_term[0] = 0 # Exclude the bias term\n",
    "                    grad = grad + regularized_term\n",
    "                \n",
    "                elif self.regularizer == 'l1':\n",
    "                    regularized_term = self.lambd * np.sign(self.w)\n",
    "                    regularized_term[0] = 0 # Exclude the bias term\n",
    "                    grad = grad + regularized_term\n",
    "            \n",
    "                # Update weights\n",
    "                    self.w = self.w - (self.learning_rate/m)*grad\n",
    "        \n",
    "        if self.plotLearningCurve is True:                  \n",
    "            # Plotting Learning Curve            \n",
    "            epochs_xaxis=np.linspace(1.0,len(self.loss_train),num=len(self.loss_train))\n",
    "            plt.figure(figsize=(12, 9), dpi=80)\n",
    "            plt.plot(epochs_xaxis,self.loss_train, label = \"Training\")\n",
    "            plt.plot(epochs_xaxis,self.loss_validation, label = \"Validation\")\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.title(\"Learning Curve\")\n",
    "            plt.legend()\n",
    "            plt.show()        \n",
    "                \n",
    "    def predict(self, X):\n",
    "        \n",
    "        x_0 = np.ones((X.shape[0],1))\n",
    "        X = np.concatenate((x_0,X), axis=1)\n",
    "        \n",
    "        pred = sigmoid(X.dot(self.w))\n",
    "        \n",
    "        # Assign 1 for p(x) > 0.5, else 0\n",
    "        pred = np.array(list(map(lambda x: 1 if x>0.5 else 0, pred)))\n",
    "        \n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A-II: Load, Partition, and Scale Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Read the Iris data using the sklearn.datasets.load_iris function. Create a data matrix X (numpy ndarray) and 1D column vector Y (numpy 1D array) containing the binary labels. Create Y by putting the value 1 if the target value Iris-Virginica, else put 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(list(map(lambda x: 1 if x==2 else 0, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Shuffle the rows of X. You may use a sklearn function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = shuffle(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Partition the data into train and test set. Use the partition function from your previous assignment or from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Standardize the train and test set. Use the standardization function from your previous assignment or from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "scaler.fit(X_test)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 960x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m1 = Logistic_Regression_Binary(learning_rate = 0.01, epochs = 1000, regularizer = 'l1', lambd = 1,early_stopping=True,plotLearningCurve=True)\n",
    "m1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Accuracy:  0.9107142857142857\n",
      "\n",
      "Train Confusion Matrix:\n",
      "[[69  8]\n",
      " [ 2 33]]\n",
      "\n",
      "Test Accuracy:  0.9210526315789473\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[21  2]\n",
      " [ 1 14]]\n",
      "\n",
      "Test Precision = 0.875000\n",
      "Test Recall = 0.933333\n",
      "Test F1 Score = 0.903226\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93        23\n",
      "           1       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.91      0.92      0.92        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_predicted = m1.predict(X_train)\n",
    "\n",
    "\n",
    "accuracy_score_train = np.mean(y_train_predicted == y_train)\n",
    "print(\"\\nTrain Accuracy: \", accuracy_score_train)\n",
    "\n",
    "print(\"\\nTrain Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, y_train_predicted))\n",
    "\n",
    "y_test_predicted = m1.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy_score_test = np.mean(y_test_predicted == y_test)\n",
    "print(\"\\nTest Accuracy: \", accuracy_score_test)\n",
    "\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted) \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted)\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted)\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.02032355  0.47691873  0.05127962  0.69586895  0.93709589]\n",
      "[0 0 0 1 0 0 1 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0\n",
      " 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0 1 0 1 1 0 1 0\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "print(m1.w)\n",
    "print(y_train_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A-III: Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Model selection via Hyperparameter tuning: Use the kFold function from previous assignment or from sklearn to evaluate the performance of your model over each combination of parameters from the following sets. You may vary the range of values, if needed, and also for more experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_calc(true, pred):\n",
    "    match = map(lambda x,y: x == y, list(true), list(pred))\n",
    "    match = map(lambda x: 1 if x else 0, list(match))\n",
    "    accuracy = np.mean(list(match))\n",
    "    generalization_error=1-accuracy\n",
    "    return accuracy,generalization_error\n",
    "\n",
    "def sFold(estimator,X,y,scoring,cv):\n",
    "    size = len(X)\n",
    "    size_fold = int(size/cv)\n",
    "    range_index = [j for j in range(0,len(X))]\n",
    "    score=[]\n",
    "    #Partitioning of the data\n",
    "    for i in range(cv):\n",
    "        init=0+i*size_fold\n",
    "        fin=(i+1)*size_fold\n",
    "        partition_range_index = [j for j in range(init,fin)]\n",
    "        \n",
    "        #Feature and label data of the Fold\n",
    "        X_partition = X[partition_range_index]\n",
    "        y_partition = y[partition_range_index]\n",
    "        \n",
    "        #Feature and label data of  1-Fold        \n",
    "        remainder_index = list(set(range_index).difference(set(partition_range_index)))\n",
    "        X_remainder=X[remainder_index]\n",
    "        y_remainder=y[remainder_index]\n",
    "        \n",
    "        #Fit the model to the 1-Fold data\n",
    "        estimator.fit(X_remainder, y_remainder) \n",
    "        \n",
    "        #Test the model on the fold data\n",
    "        pred=estimator.predict(X_partition)\n",
    "      \n",
    "        if scoring=='accuracy':\n",
    "            acc,gen_error=accuracy_calc(y_partition,pred)\n",
    "            score.append(acc) \n",
    "            \n",
    "    avg_score = np.mean(score)    \n",
    "    return avg_score,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "Early stopping because the validation loss is not decreasing\n",
      "{'Lambda_1.0_Learning Rate_0.1_Regularizer_l1_Epochs_1000': (0.9, [0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.9090909090909091, 1.0, 0.9090909090909091, 0.9090909090909091, 0.9090909090909091, 1.0, 1.0]), 'Lambda_1.0_Learning Rate_0.1_Regularizer_l2_Epochs_1000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_1.0_Learning Rate_0.01_Regularizer_l1_Epochs_1000': (0.909090909090909, [0.7272727272727273, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 1.0, 0.9090909090909091, 1.0, 0.9090909090909091, 1.0, 1.0]), 'Lambda_1.0_Learning Rate_0.01_Regularizer_l2_Epochs_1000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_1.0_Learning Rate_0.001_Regularizer_l1_Epochs_1000': (0.8181818181818181, [0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 1.0, 0.7272727272727273, 0.9090909090909091, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182]), 'Lambda_1.0_Learning Rate_0.001_Regularizer_l2_Epochs_1000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_1.0_Learning Rate_0.1_Regularizer_l1_Epochs_10000': (0.8636363636363636, [0.7272727272727273, 1.0, 0.7272727272727273, 0.8181818181818182, 1.0, 0.9090909090909091, 0.9090909090909091, 0.7272727272727273, 0.8181818181818182, 1.0]), 'Lambda_1.0_Learning Rate_0.1_Regularizer_l2_Epochs_10000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_1.0_Learning Rate_0.01_Regularizer_l1_Epochs_10000': (0.890909090909091, [0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 1.0, 0.9090909090909091, 0.9090909090909091, 0.9090909090909091, 1.0, 1.0]), 'Lambda_1.0_Learning Rate_0.01_Regularizer_l2_Epochs_10000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_1.0_Learning Rate_0.001_Regularizer_l1_Epochs_10000': (0.8909090909090909, [0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 1.0, 0.9090909090909091, 1.0, 0.9090909090909091, 1.0, 0.9090909090909091]), 'Lambda_1.0_Learning Rate_0.001_Regularizer_l2_Epochs_10000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0_Learning Rate_0.1_Regularizer_l1_Epochs_1000': (0.9545454545454547, [0.8181818181818182, 1.0, 0.9090909090909091, 0.9090909090909091, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0]), 'Lambda_0_Learning Rate_0.1_Regularizer_l2_Epochs_1000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0_Learning Rate_0.01_Regularizer_l1_Epochs_1000': (0.9, [0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 1.0, 0.9090909090909091, 1.0, 0.9090909090909091, 1.0, 1.0]), 'Lambda_0_Learning Rate_0.01_Regularizer_l2_Epochs_1000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0_Learning Rate_0.001_Regularizer_l1_Epochs_1000': (0.809090909090909, [0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.9090909090909091, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182]), 'Lambda_0_Learning Rate_0.001_Regularizer_l2_Epochs_1000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0_Learning Rate_0.1_Regularizer_l1_Epochs_10000': (0.9636363636363636, [0.9090909090909091, 1.0, 0.8181818181818182, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0]), 'Lambda_0_Learning Rate_0.1_Regularizer_l2_Epochs_10000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0_Learning Rate_0.01_Regularizer_l1_Epochs_10000': (0.9636363636363636, [0.8181818181818182, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0]), 'Lambda_0_Learning Rate_0.01_Regularizer_l2_Epochs_10000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0_Learning Rate_0.001_Regularizer_l1_Epochs_10000': (0.9, [0.7272727272727273, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 1.0, 0.9090909090909091, 0.9090909090909091, 0.9090909090909091, 1.0, 1.0]), 'Lambda_0_Learning Rate_0.001_Regularizer_l2_Epochs_10000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.1_Learning Rate_0.1_Regularizer_l1_Epochs_1000': (0.9545454545454547, [0.8181818181818182, 1.0, 0.9090909090909091, 0.9090909090909091, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0]), 'Lambda_0.1_Learning Rate_0.1_Regularizer_l2_Epochs_1000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.1_Learning Rate_0.01_Regularizer_l1_Epochs_1000': (0.890909090909091, [0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 1.0, 0.9090909090909091, 1.0, 0.9090909090909091, 0.9090909090909091, 1.0]), 'Lambda_0.1_Learning Rate_0.01_Regularizer_l2_Epochs_1000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.1_Learning Rate_0.001_Regularizer_l1_Epochs_1000': (0.8181818181818181, [0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 1.0, 0.7272727272727273, 0.9090909090909091, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182]), 'Lambda_0.1_Learning Rate_0.001_Regularizer_l2_Epochs_1000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.1_Learning Rate_0.1_Regularizer_l1_Epochs_10000': (0.9636363636363636, [0.9090909090909091, 1.0, 0.9090909090909091, 0.9090909090909091, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0]), 'Lambda_0.1_Learning Rate_0.1_Regularizer_l2_Epochs_10000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.1_Learning Rate_0.01_Regularizer_l1_Epochs_10000': (0.9545454545454547, [0.8181818181818182, 1.0, 0.9090909090909091, 0.9090909090909091, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0]), 'Lambda_0.1_Learning Rate_0.01_Regularizer_l2_Epochs_10000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.1_Learning Rate_0.001_Regularizer_l1_Epochs_10000': (0.9181818181818182, [0.7272727272727273, 1.0, 0.8181818181818182, 0.8181818181818182, 1.0, 0.9090909090909091, 1.0, 0.9090909090909091, 1.0, 1.0]), 'Lambda_0.1_Learning Rate_0.001_Regularizer_l2_Epochs_10000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.01_Learning Rate_0.1_Regularizer_l1_Epochs_1000': (0.9545454545454547, [0.8181818181818182, 1.0, 0.9090909090909091, 0.9090909090909091, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0]), 'Lambda_0.01_Learning Rate_0.1_Regularizer_l2_Epochs_1000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.01_Learning Rate_0.01_Regularizer_l1_Epochs_1000': (0.8818181818181818, [0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 1.0, 0.9090909090909091, 0.9090909090909091, 0.9090909090909091, 0.9090909090909091, 1.0]), 'Lambda_0.01_Learning Rate_0.01_Regularizer_l2_Epochs_1000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.01_Learning Rate_0.001_Regularizer_l1_Epochs_1000': (0.8181818181818181, [0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 1.0, 0.7272727272727273, 0.9090909090909091, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182]), 'Lambda_0.01_Learning Rate_0.001_Regularizer_l2_Epochs_1000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.01_Learning Rate_0.1_Regularizer_l1_Epochs_10000': (0.9636363636363636, [0.9090909090909091, 1.0, 0.9090909090909091, 0.9090909090909091, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0]), 'Lambda_0.01_Learning Rate_0.1_Regularizer_l2_Epochs_10000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.01_Learning Rate_0.01_Regularizer_l1_Epochs_10000': (0.9454545454545455, [0.8181818181818182, 0.9090909090909091, 0.9090909090909091, 0.9090909090909091, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0]), 'Lambda_0.01_Learning Rate_0.01_Regularizer_l2_Epochs_10000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.01_Learning Rate_0.001_Regularizer_l1_Epochs_10000': (0.8818181818181818, [0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 1.0, 0.9090909090909091, 0.9090909090909091, 0.9090909090909091, 0.9090909090909091, 1.0]), 'Lambda_0.01_Learning Rate_0.001_Regularizer_l2_Epochs_10000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.001_Learning Rate_0.1_Regularizer_l1_Epochs_1000': (0.9454545454545455, [0.8181818181818182, 0.9090909090909091, 0.9090909090909091, 0.9090909090909091, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0]), 'Lambda_0.001_Learning Rate_0.1_Regularizer_l2_Epochs_1000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.001_Learning Rate_0.01_Regularizer_l1_Epochs_1000': (0.890909090909091, [0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 1.0, 0.9090909090909091, 1.0, 0.9090909090909091, 0.9090909090909091, 1.0]), 'Lambda_0.001_Learning Rate_0.01_Regularizer_l2_Epochs_1000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.001_Learning Rate_0.001_Regularizer_l1_Epochs_1000': (0.8181818181818181, [0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 1.0, 0.7272727272727273, 0.9090909090909091, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182]), 'Lambda_0.001_Learning Rate_0.001_Regularizer_l2_Epochs_1000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.001_Learning Rate_0.1_Regularizer_l1_Epochs_10000': (0.9727272727272727, [0.9090909090909091, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0]), 'Lambda_0.001_Learning Rate_0.1_Regularizer_l2_Epochs_10000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.001_Learning Rate_0.01_Regularizer_l1_Epochs_10000': (0.9545454545454547, [0.8181818181818182, 1.0, 0.9090909090909091, 0.9090909090909091, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0]), 'Lambda_0.001_Learning Rate_0.01_Regularizer_l2_Epochs_10000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.001_Learning Rate_0.001_Regularizer_l1_Epochs_10000': (0.9, [0.7272727272727273, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 1.0, 0.9090909090909091, 1.0, 0.9090909090909091, 0.9090909090909091, 1.0]), 'Lambda_0.001_Learning Rate_0.001_Regularizer_l2_Epochs_10000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.0001_Learning Rate_0.1_Regularizer_l1_Epochs_1000': (0.9545454545454547, [0.8181818181818182, 1.0, 0.9090909090909091, 0.9090909090909091, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0]), 'Lambda_0.0001_Learning Rate_0.1_Regularizer_l2_Epochs_1000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.0001_Learning Rate_0.01_Regularizer_l1_Epochs_1000': (0.890909090909091, [0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 1.0, 0.9090909090909091, 1.0, 0.9090909090909091, 0.9090909090909091, 1.0]), 'Lambda_0.0001_Learning Rate_0.01_Regularizer_l2_Epochs_1000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.0001_Learning Rate_0.001_Regularizer_l1_Epochs_1000': (0.8181818181818181, [0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 1.0, 0.7272727272727273, 0.9090909090909091, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182]), 'Lambda_0.0001_Learning Rate_0.001_Regularizer_l2_Epochs_1000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.0001_Learning Rate_0.1_Regularizer_l1_Epochs_10000': (0.9818181818181818, [0.9090909090909091, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), 'Lambda_0.0001_Learning Rate_0.1_Regularizer_l2_Epochs_10000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.0001_Learning Rate_0.01_Regularizer_l1_Epochs_10000': (0.9545454545454547, [0.8181818181818182, 1.0, 0.9090909090909091, 0.9090909090909091, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0]), 'Lambda_0.0001_Learning Rate_0.01_Regularizer_l2_Epochs_10000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365]), 'Lambda_0.0001_Learning Rate_0.001_Regularizer_l1_Epochs_10000': (0.9, [0.7272727272727273, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 1.0, 0.9090909090909091, 1.0, 0.9090909090909091, 0.9090909090909091, 1.0]), 'Lambda_0.0001_Learning Rate_0.001_Regularizer_l2_Epochs_10000': (0.6909090909090909, [0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365])}\n"
     ]
    }
   ],
   "source": [
    "lambd =[1.0,0,0.1,0.01,0.001,0.0001] \n",
    "epoch=[1000,10000]\n",
    "learning_rate =[0.1, 0.01, 0.001, 0.001]\n",
    "regularizer = ['l1', 'l2']\n",
    "cv=10\n",
    "\n",
    "results = {}\n",
    "\n",
    "for lam in lambd:\n",
    "    for epo in epoch:\n",
    "        for eta in learning_rate:\n",
    "            for reg in regularizer:\n",
    "                label ='Lambda'+'_'+str(lam) + '_'+'Learning Rate'+'_'+ str(eta) +'_'+'Regularizer'+'_'+str(reg)+'_'+'Epochs'+'_'+ str(epo)\n",
    "                model=Logistic_Regression_Binary(learning_rate = eta, epochs = epo, regularizer = reg, lambd = lam, early_stopping=True, plotLearningCurve=False)\n",
    "                results[label] = sFold(model,X_train,y_train,scoring='accuracy',cv=cv)\n",
    "                \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda_1.0_Learning Rate_0.1_Regularizer_l1_Epochs_1000: Accuracy 0.890909090909091\n",
      "Lambda_1.0_Learning Rate_0.1_Regularizer_l2_Epochs_1000: Accuracy 0.6909090909090909\n",
      "Lambda_1.0_Learning Rate_0.01_Regularizer_l1_Epochs_1000: Accuracy 0.890909090909091\n",
      "Lambda_1.0_Learning Rate_0.01_Regularizer_l2_Epochs_1000: Accuracy 0.6909090909090909\n",
      "Lambda_1.0_Learning Rate_0.001_Regularizer_l1_Epochs_1000: Accuracy 0.8181818181818181\n",
      "Lambda_1.0_Learning Rate_0.001_Regularizer_l2_Epochs_1000: Accuracy 0.6909090909090909\n",
      "Lambda_1.0_Learning Rate_0.1_Regularizer_l1_Epochs_10000: Accuracy 0.8818181818181818\n",
      "Lambda_1.0_Learning Rate_0.1_Regularizer_l2_Epochs_10000: Accuracy 0.6909090909090909\n",
      "Lambda_1.0_Learning Rate_0.01_Regularizer_l1_Epochs_10000: Accuracy 0.9\n",
      "Lambda_1.0_Learning Rate_0.01_Regularizer_l2_Epochs_10000: Accuracy 0.6909090909090909\n",
      "Lambda_1.0_Learning Rate_0.001_Regularizer_l1_Epochs_10000: Accuracy 0.9\n",
      "Lambda_1.0_Learning Rate_0.001_Regularizer_l2_Epochs_10000: Accuracy 0.6909090909090909\n",
      "Lambda_0_Learning Rate_0.1_Regularizer_l1_Epochs_1000: Accuracy 0.9545454545454547\n",
      "Lambda_0_Learning Rate_0.1_Regularizer_l2_Epochs_1000: Accuracy 0.6909090909090909\n",
      "Lambda_0_Learning Rate_0.01_Regularizer_l1_Epochs_1000: Accuracy 0.890909090909091\n",
      "Lambda_0_Learning Rate_0.01_Regularizer_l2_Epochs_1000: Accuracy 0.6909090909090909\n",
      "Lambda_0_Learning Rate_0.001_Regularizer_l1_Epochs_1000: Accuracy 0.8181818181818181\n",
      "Lambda_0_Learning Rate_0.001_Regularizer_l2_Epochs_1000: Accuracy 0.6909090909090909\n",
      "Lambda_0_Learning Rate_0.1_Regularizer_l1_Epochs_10000: Accuracy 0.9818181818181818\n",
      "Lambda_0_Learning Rate_0.1_Regularizer_l2_Epochs_10000: Accuracy 0.6909090909090909\n",
      "Lambda_0_Learning Rate_0.01_Regularizer_l1_Epochs_10000: Accuracy 0.9545454545454547\n",
      "Lambda_0_Learning Rate_0.01_Regularizer_l2_Epochs_10000: Accuracy 0.6909090909090909\n",
      "Lambda_0_Learning Rate_0.001_Regularizer_l1_Epochs_10000: Accuracy 0.9\n",
      "Lambda_0_Learning Rate_0.001_Regularizer_l2_Epochs_10000: Accuracy 0.6909090909090909\n",
      "Lambda_0.1_Learning Rate_0.1_Regularizer_l1_Epochs_1000: Accuracy 0.9363636363636363\n",
      "Lambda_0.1_Learning Rate_0.1_Regularizer_l2_Epochs_1000: Accuracy 0.6909090909090909\n",
      "Lambda_0.1_Learning Rate_0.01_Regularizer_l1_Epochs_1000: Accuracy 0.9\n",
      "Lambda_0.1_Learning Rate_0.01_Regularizer_l2_Epochs_1000: Accuracy 0.6909090909090909\n",
      "Lambda_0.1_Learning Rate_0.001_Regularizer_l1_Epochs_1000: Accuracy 0.809090909090909\n",
      "Lambda_0.1_Learning Rate_0.001_Regularizer_l2_Epochs_1000: Accuracy 0.6909090909090909\n",
      "Lambda_0.1_Learning Rate_0.1_Regularizer_l1_Epochs_10000: Accuracy 0.9636363636363636\n",
      "Lambda_0.1_Learning Rate_0.1_Regularizer_l2_Epochs_10000: Accuracy 0.6909090909090909\n",
      "Lambda_0.1_Learning Rate_0.01_Regularizer_l1_Epochs_10000: Accuracy 0.9363636363636363\n",
      "Lambda_0.1_Learning Rate_0.01_Regularizer_l2_Epochs_10000: Accuracy 0.6909090909090909\n",
      "Lambda_0.1_Learning Rate_0.001_Regularizer_l1_Epochs_10000: Accuracy 0.909090909090909\n",
      "Lambda_0.1_Learning Rate_0.001_Regularizer_l2_Epochs_10000: Accuracy 0.6909090909090909\n",
      "Lambda_0.01_Learning Rate_0.1_Regularizer_l1_Epochs_1000: Accuracy 0.9545454545454547\n",
      "Lambda_0.01_Learning Rate_0.1_Regularizer_l2_Epochs_1000: Accuracy 0.6909090909090909\n",
      "Lambda_0.01_Learning Rate_0.01_Regularizer_l1_Epochs_1000: Accuracy 0.890909090909091\n",
      "Lambda_0.01_Learning Rate_0.01_Regularizer_l2_Epochs_1000: Accuracy 0.6909090909090909\n",
      "Lambda_0.01_Learning Rate_0.001_Regularizer_l1_Epochs_1000: Accuracy 0.809090909090909\n",
      "Lambda_0.01_Learning Rate_0.001_Regularizer_l2_Epochs_1000: Accuracy 0.6909090909090909\n",
      "Lambda_0.01_Learning Rate_0.1_Regularizer_l1_Epochs_10000: Accuracy 0.9727272727272727\n",
      "Lambda_0.01_Learning Rate_0.1_Regularizer_l2_Epochs_10000: Accuracy 0.6909090909090909\n",
      "Lambda_0.01_Learning Rate_0.01_Regularizer_l1_Epochs_10000: Accuracy 0.9545454545454547\n",
      "Lambda_0.01_Learning Rate_0.01_Regularizer_l2_Epochs_10000: Accuracy 0.6909090909090909\n",
      "Lambda_0.01_Learning Rate_0.001_Regularizer_l1_Epochs_10000: Accuracy 0.9\n",
      "Lambda_0.01_Learning Rate_0.001_Regularizer_l2_Epochs_10000: Accuracy 0.6909090909090909\n",
      "Lambda_0.001_Learning Rate_0.1_Regularizer_l1_Epochs_1000: Accuracy 0.9454545454545455\n",
      "Lambda_0.001_Learning Rate_0.1_Regularizer_l2_Epochs_1000: Accuracy 0.6909090909090909\n",
      "Lambda_0.001_Learning Rate_0.01_Regularizer_l1_Epochs_1000: Accuracy 0.9\n",
      "Lambda_0.001_Learning Rate_0.01_Regularizer_l2_Epochs_1000: Accuracy 0.6909090909090909\n",
      "Lambda_0.001_Learning Rate_0.001_Regularizer_l1_Epochs_1000: Accuracy 0.809090909090909\n",
      "Lambda_0.001_Learning Rate_0.001_Regularizer_l2_Epochs_1000: Accuracy 0.6909090909090909\n",
      "Lambda_0.001_Learning Rate_0.1_Regularizer_l1_Epochs_10000: Accuracy 0.9727272727272727\n",
      "Lambda_0.001_Learning Rate_0.1_Regularizer_l2_Epochs_10000: Accuracy 0.6909090909090909\n",
      "Lambda_0.001_Learning Rate_0.01_Regularizer_l1_Epochs_10000: Accuracy 0.9545454545454547\n",
      "Lambda_0.001_Learning Rate_0.01_Regularizer_l2_Epochs_10000: Accuracy 0.6909090909090909\n",
      "Lambda_0.001_Learning Rate_0.001_Regularizer_l1_Epochs_10000: Accuracy 0.890909090909091\n",
      "Lambda_0.001_Learning Rate_0.001_Regularizer_l2_Epochs_10000: Accuracy 0.6909090909090909\n",
      "Lambda_0.0001_Learning Rate_0.1_Regularizer_l1_Epochs_1000: Accuracy 0.9545454545454547\n",
      "Lambda_0.0001_Learning Rate_0.1_Regularizer_l2_Epochs_1000: Accuracy 0.6909090909090909\n",
      "Lambda_0.0001_Learning Rate_0.01_Regularizer_l1_Epochs_1000: Accuracy 0.890909090909091\n",
      "Lambda_0.0001_Learning Rate_0.01_Regularizer_l2_Epochs_1000: Accuracy 0.6909090909090909\n",
      "Lambda_0.0001_Learning Rate_0.001_Regularizer_l1_Epochs_1000: Accuracy 0.8181818181818181\n",
      "Lambda_0.0001_Learning Rate_0.001_Regularizer_l2_Epochs_1000: Accuracy 0.6909090909090909\n",
      "Lambda_0.0001_Learning Rate_0.1_Regularizer_l1_Epochs_10000: Accuracy 0.9818181818181818\n",
      "Lambda_0.0001_Learning Rate_0.1_Regularizer_l2_Epochs_10000: Accuracy 0.6909090909090909\n",
      "Lambda_0.0001_Learning Rate_0.01_Regularizer_l1_Epochs_10000: Accuracy 0.9545454545454547\n",
      "Lambda_0.0001_Learning Rate_0.01_Regularizer_l2_Epochs_10000: Accuracy 0.6909090909090909\n",
      "Lambda_0.0001_Learning Rate_0.001_Regularizer_l1_Epochs_10000: Accuracy 0.9\n",
      "Lambda_0.0001_Learning Rate_0.001_Regularizer_l2_Epochs_10000: Accuracy 0.6909090909090909\n",
      "0.9818181818181818\n",
      "Lambda_0_Learning Rate_0.1_Regularizer_l1_Epochs_10000\n"
     ]
    }
   ],
   "source": [
    "max_acc =0\n",
    "min_config = ''\n",
    "for key,pair in results.items():\n",
    "    print(key + \": Accuracy \" + str(pair[0]))\n",
    "    if pair[0] >max_acc:\n",
    "        max_acc=pair[0]\n",
    "        max_config=key\n",
    "print(max_acc)\n",
    "print(max_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Evaluate your best model on the test data and report the accuracy and confusion matrix. You may use the sklearn.metrics.confusion_matrix function for generating the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 960x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Accuracy:  0.9821428571428571\n",
      "\n",
      "Train Confusion Matrix:\n",
      "[[76  1]\n",
      " [ 1 34]]\n",
      "\n",
      "Test Accuracy:  0.9210526315789473\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[23  0]\n",
      " [ 3 12]]\n",
      "\n",
      "Test Precision = 1.000000\n",
      "Test Recall = 0.800000\n",
      "Test F1 Score = 0.888889\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94        23\n",
      "           1       1.00      0.80      0.89        15\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.94      0.90      0.91        38\n",
      "weighted avg       0.93      0.92      0.92        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Best Model\n",
    "#Regularizer: L1\n",
    "#Learning Rate: 0.1\n",
    "#Lambda: 0\n",
    "#Epochs: 10000\n",
    "\n",
    "model = Logistic_Regression_Binary(learning_rate = 0.1, epochs = 10000, regularizer = 'l1', lambd = 0,early_stopping=True,plotLearningCurve=True)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_train_predicted=model.predict(X_train)\n",
    "\n",
    "y_test_predicted=model.predict(X_test)\n",
    "\n",
    "#Confusion Matrix\n",
    "\n",
    "accuracy_score_train = np.mean(y_train_predicted == y_train)\n",
    "print(\"\\nTrain Accuracy: \", accuracy_score_train)\n",
    "\n",
    "print(\"\\nTrain Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, y_train_predicted))\n",
    "\n",
    "\n",
    "accuracy_score_test = np.mean(y_test_predicted == y_test)\n",
    "print(\"\\nTest Accuracy: \", accuracy_score_test)\n",
    "\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted) \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted)\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted)\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9821428571428571\n"
     ]
    }
   ],
   "source": [
    "acc,gen_error=accuracy_calc(y_train_predicted,y_train)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Using the best model, report the following in the Jupyter notebook: total number of iterations before the model converged, the final weightvector, and the learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B-I: Model Code Logistic Regression-Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Implement the following function to convert the vector of class labels into a matrix containing a one-hot vector for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_labels(Y):\n",
    "    \n",
    "    # Get unique labels in Y and number of observations\n",
    "    unique_labels = np.unique(Y)\n",
    "    n = len(Y)\n",
    "    \n",
    "    # Create one hot matrix\n",
    "    labels = np.array(list(unique_labels)).reshape(len(unique_labels),1)\n",
    "    one_hot_matrix = np.apply_along_axis(lambda x: np.full((n,),x),1,labels)\n",
    "    one_hot_matrix = np.apply_along_axis(lambda x: (x==Y).astype(int),1,one_hot_matrix).T\n",
    "    \n",
    "    return one_hot_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(['hi', 'no', 'no', 'hi','yes','yes','yes','bye','bye','no','hi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(Y).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = np.unique(Y)\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(list(unique_labels)).reshape(len(unique_labels),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = one_hot_labels(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(one_hot_labels(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Implement the following function that computes the softmax score or the normalized exponential of the score of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(score):\n",
    "    score = np.apply_along_axis(np.exp,0,score)\n",
    "    score = np.apply_along_axis(lambda x: x/(sum(x)),1,score)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Implement the following function to compute the cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(Y_one_hot, Y_proba):\n",
    "    loss = -np.sum(np.multiply(Y_one_hot,np.log(Y_proba)))/Y_one_hot.shape[0]\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_loss(Y_train,softmax(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Implement the following function to compute the l2 regularized cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss_l2(Y_one_hot, Y_proba, Theta, lambd):\n",
    "    loss = cross_entropy_loss(Y_one_hot, Y_proba) + 0.5*lambd*np.sum(np.square(Theta[1:]))/Y_one_hot.shape[0]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Implement the following function to compute the l1 regularized cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss_l1(Y_one_hot, Y_proba, Theta, lambd):\n",
    "    loss = cross_entropy_loss(Y_one_hot, Y_proba) + lambd*np.sum(abs(Theta[1:]))/Y_one_hot.shape[0]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Implement a Logistic_Regression_Multiclass model class that uses the softmax regression technique for performing multi-class classification. The model should have the following three methods. Note the that “fit” method should implement the batch gradient descent algorithm (based on the 1st order derivative of the loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic_Regression_Multiclass():\n",
    "    def __init__(self, multi_class='softmax', learning_rate=0.01, epochs=100, tol=0.0001, regularizer=None, lambd=0.0, early_stopping=False, validation_fraction=0.1, plotLearningCurve=True, **kwargs):\n",
    "        self.multi_class = multi_class\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.tol = tol\n",
    "        self.regularizer = regularizer\n",
    "        self.lambd = lambd\n",
    "        self.early_stopping = early_stopping\n",
    "        self.validation_fraction = validation_fraction\n",
    "        self.plotLearningCurve = plotLearningCurve\n",
    "        self.W = None\n",
    "        self.loss = []\n",
    "        self.loss_validation = []\n",
    "        \n",
    "    def fit(self,X,Y):\n",
    "        # Add 1 for bias term\n",
    "        x_0 = np.ones((X.shape[0],1))\n",
    "        X = np.concatenate((x_0,X), axis=1)\n",
    "        \n",
    "        if self.early_stopping:\n",
    "            valid_samples = math.floor(X.shape[0]*self.validation_fraction)\n",
    "            validation_X = X[:valid_samples]\n",
    "            X = X[valid_samples:]\n",
    "            validation_Y = Y[:valid_samples]\n",
    "            Y = Y[valid_samples:]\n",
    "        \n",
    "        # Set number of training data\n",
    "        n = X.shape[0]\n",
    "        \n",
    "        # Initiate Weight Matrix\n",
    "        W = np.zeros((X.shape[1],Y.shape[1]))\n",
    "        \n",
    "        loss = []\n",
    "        loss_validation = []\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            # Prediction\n",
    "            Mu = softmax(X.dot(W))\n",
    "            \n",
    "            if self.early_stopping:\n",
    "                Mu_validate = softmax(validation_X.dot(W))\n",
    "            \n",
    "            if self.regularizer == 'l2':\n",
    "                G = self.lambd*np.sum(np.square(W[1:])) \n",
    "                l = cross_entropy_loss_l2(Y,Mu,W,self.lambd)\n",
    "                if self.early_stopping:\n",
    "                    l_val = cross_entropy_loss_l2(validation_Y,Mu_validate,W,self.lambd)\n",
    "            elif self.regularizer == 'l1':\n",
    "                G = self.lambd*np.sum(np.sign(W[1:]))\n",
    "                l = cross_entropy_loss_l1(Y,Mu,W,self.lambd)\n",
    "                if self.early_stopping:\n",
    "                    l_val = cross_entropy_loss_l2(validation_Y,Mu_validate,W,self.lambd)\n",
    "            elif self.regularizer is None:\n",
    "                G = 0\n",
    "                l = cross_entropy_loss(Y,Mu)\n",
    "                if self.early_stopping:\n",
    "                    l_val = cross_entropy_loss(validation_Y,Mu_validate)\n",
    "                \n",
    "            loss.append(l)\n",
    "            \n",
    "            if self.early_stopping:\n",
    "                loss_validation.append(l_val)\n",
    "            \n",
    "            # Early stopping correction\n",
    "            if self.early_stopping:\n",
    "                if len(loss_validation) > 1:\n",
    "                    if loss_validation[-2] - loss_validation[-1] < 0:\n",
    "                        break\n",
    "                    \n",
    "            \n",
    "            # Calculate first degree gradient derivative\n",
    "            G = G + X.T.dot(softmax(X.dot(W))-Y)\n",
    "            \n",
    "            if self.regularizer == 'l2':\n",
    "                G = G + self.lambd*np.sum(np.square(W[1:])) \n",
    "            elif self.regularizer == 'l1':\n",
    "                G = G + self.lambd*np.sum(np.sign(W[1:])) \n",
    "            \n",
    "            # Update weights\n",
    "            W = W - (self.learning_rate/n)*G            \n",
    "            \n",
    "        self.W = W\n",
    "        self.loss = loss\n",
    "        self.loss_validation = loss_validation\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    def predict(self,X):\n",
    "        # Append bias term\n",
    "        x_0 = np.ones((X.shape[0],1))\n",
    "        X = np.concatenate((x_0,X), axis=1)\n",
    "        \n",
    "        return softmax(X.dot(self.W))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = Logistic_Regression_Multiclass(learning_rate=0.1, epochs=1000, regularizer='l2', lambd = 0.1, early_stopping = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_validation = logit.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B-II: Load, Partition, and Scale Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Read the Iris data using the sklearn.datasets.load_iris function. Create a data matrix X and 1D column vector Y containing the multi-lass labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Shuffle the rows of X. You may use a sklearn function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Partition the data into train and test set. Use the partition function from your previous assignment or from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. Standardize the train and test set. Use the standardization function from your previous assignment or from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B-III: Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. Model selection via Hyperparameter tuning: Use the kFold function from previous assignment or from sklearn to evaluate the performance of your model over each combination of parameters from the following sets. You may vary the range of values, if needed, and also for more experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24. Evaluate your best model on the test data and report the accuracy and confusion matrix. You may use the sklearn.metrics.confusion_matrix function for generating the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25. Using the best model, report the following in the Jupyter notebook: total number of iterations before the model converged, the final weightvector, and the learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26. Implement the one-vs-all (OvA) technique for performing multi-class classification in the Logistic_Regression_Multiclass model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27. Implement the Stochastic Gradient Descent Logistic Regression algorithm for performing multi-class classification. It should use a suitable learning schedule function for adapting the learning rate. Using cross-validation determine the best model. Evaluate your model on test data and report the accuracy and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
